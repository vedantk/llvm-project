; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -protect-libcalls -S %s -o - | FileCheck %s
; RUN: opt -passes=protect-libcalls -S %s -o - | FileCheck %s

target datalayout = "e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-apple-macosx10.14.0"

declare i8* @malloc(i64) allocsize(0)
declare i8* @calloc(i64, i64) allocsize(0, 1)
declare i8* @realloc(i8*, i64) allocsize(1)

define i8* @malloc_of_undef() {
; CHECK-LABEL: @malloc_of_undef(
; CHECK-NEXT:    br i1 true, label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 undef)
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %call = call i8* @malloc(i64 undef)
  ret i8* %call
}

define i8* @calloc_of_undefop1() {
; CHECK-LABEL: @calloc_of_undefop1(
; CHECK-NEXT:    br i1 true, label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @calloc(i64 undef, i64 1)
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %call = call i8* @calloc(i64 undef, i64 1)
  ret i8* %call
}

define i8* @calloc_of_undefop2() {
; CHECK-LABEL: @calloc_of_undefop2(
; CHECK-NEXT:    br i1 true, label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @calloc(i64 1, i64 undef)
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %call = call i8* @calloc(i64 1, i64 undef)
  ret i8* %call
}

define i8* @realloc_of_undef(i8* %p) {
; CHECK-LABEL: @realloc_of_undef(
; CHECK-NEXT:    br i1 true, label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @realloc(i8* [[P:%.*]], i64 undef)
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %call = call i8* @realloc(i8* %p, i64 undef)
  ret i8* %call
}

define void @static_alloca() {
; CHECK-LABEL: @static_alloca(
; CHECK-NEXT:    [[A:%.*]] = alloca i32, align 4
; CHECK-NEXT:    ret void
;
  %a = alloca i32
  ret void
}

define void @static_alloca_array() {
; CHECK-LABEL: @static_alloca_array(
; CHECK-NEXT:    [[A:%.*]] = alloca i32, i32 4, align 4
; CHECK-NEXT:    ret void
;
  %a = alloca i32, i32 4
  ret void
}

define void @vla(i32 %n) {
; CHECK-LABEL: @vla(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i32, i1 } @llvm.uadd.with.overflow.i32(i32 [[N:%.*]], i32 1)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i32, i1 } [[TMP1]], 1
; CHECK-NEXT:    br i1 [[TMP2]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    ret void
;
  %a = add i32 %n, 1
  %b = alloca i32, i32 %a
  ret void
}

define i8* @malloc_of_add(i64 %a) {
; CHECK-LABEL: @malloc_of_add(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 [[A:%.*]], i64 1)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    br i1 [[TMP3]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP2]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = add nsw i64 %a, 1
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_add_negative(i64 %a) {
; CHECK-LABEL: @malloc_of_add_negative(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 [[A:%.*]], i64 -1)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    br i1 [[TMP3]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP2]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = add i64 %a, -1
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_sub(i64 %a) {
; CHECK-LABEL: @malloc_of_sub(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 [[A:%.*]], i64 1)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    br i1 [[TMP3]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP2]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = sub nsw i64 %a, 1
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_mul(i64 %a) {
; CHECK-LABEL: @malloc_of_mul(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 [[A:%.*]], i64 2)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    br i1 [[TMP3]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP2]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = mul nsw i64 %a, 2
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_add_wrapping(i64 %a) {
; CHECK-LABEL: @malloc_of_add_wrapping(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.uadd.with.overflow.i64(i64 [[A:%.*]], i64 1)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    br i1 [[TMP3]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP2]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = add i64 %a, 1
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_add_nuw(i64 %a) {
; CHECK-LABEL: @malloc_of_add_nuw(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.uadd.with.overflow.i64(i64 [[A:%.*]], i64 1)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    br i1 [[TMP3]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP2]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = add nuw i64 %a, 1
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_shl_wrapping(i64 %a) {
; CHECK-LABEL: @malloc_of_shl_wrapping(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 [[A:%.*]], i64 2)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    br i1 [[TMP3]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP2]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = shl i64 %a, 1
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_shl_nuw(i64 %a) {
; CHECK-LABEL: @malloc_of_shl_nuw(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 [[A:%.*]], i64 2)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    br i1 [[TMP3]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP2]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = shl nuw i64 %a, 1
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_shl_bad_shamt(i64 %a) {
; CHECK-LABEL: @malloc_of_shl_bad_shamt(
; CHECK-NEXT:    br i1 true, label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 undef)
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = shl nsw i64 %a, 64
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_shl_pow2_base1(i64 %a) {
; CHECK-LABEL: @malloc_of_shl_pow2_base1(
; CHECK-NEXT:    [[B:%.*]] = shl nsw i64 1, [[A:%.*]]
; CHECK-NEXT:    [[SHAMT_VALID:%.*]] = icmp uge i64 [[A]], 64
; CHECK-NEXT:    br i1 [[SHAMT_VALID]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[B]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = shl nsw i64 1, %a
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_shl_pow2_base2(i64 %a) {
; CHECK-LABEL: @malloc_of_shl_pow2_base2(
; CHECK-NEXT:    [[B:%.*]] = shl nsw i64 1024, [[A:%.*]]
; CHECK-NEXT:    [[SHAMT_VALID:%.*]] = icmp uge i64 [[A]], 54
; CHECK-NEXT:    br i1 [[SHAMT_VALID]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[B]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = shl nsw i64 1024, %a
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_shl_non_pow2_base(i64 %a) {
; CHECK-LABEL: @malloc_of_shl_non_pow2_base(
; CHECK-NEXT:    [[SHAMT_AS_MULTIPLIER:%.*]] = shl nuw nsw i64 1, [[A:%.*]]
; CHECK-NEXT:    [[SHAMT_VALID:%.*]] = icmp uge i64 [[A]], 64
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 3, i64 [[SHAMT_AS_MULTIPLIER]])
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    [[TMP4:%.*]] = or i1 [[TMP3]], [[SHAMT_VALID]]
; CHECK-NEXT:    br i1 [[TMP4]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP2]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = shl nsw i64 3, %a
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

define i8* @malloc_of_shl(i64 %a, i64 %shamt) {
; CHECK-LABEL: @malloc_of_shl(
; CHECK-NEXT:    [[SHAMT_AS_MULTIPLIER:%.*]] = shl nuw nsw i64 1, [[SHAMT:%.*]]
; CHECK-NEXT:    [[SHAMT_VALID:%.*]] = icmp uge i64 [[SHAMT]], 64
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 [[A:%.*]], i64 [[SHAMT_AS_MULTIPLIER]])
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    [[TMP4:%.*]] = or i1 [[TMP3]], [[SHAMT_VALID]]
; CHECK-NEXT:    br i1 [[TMP4]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP2]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = shl nsw i64 %a, %shamt
  %call = call i8* @malloc(i64 %b)
  ret i8* %call
}

; CGP duplicates the icmp, even though an attempt is made to reuse it.
define i8* @malloc_of_shl_pow2_reused(i64 %a) {
; CHECK-LABEL: @malloc_of_shl_pow2_reused(
; CHECK-NEXT:    [[B:%.*]] = shl nsw i64 1024, [[A:%.*]]
; CHECK-NEXT:    [[SHAMT_VALID:%.*]] = icmp uge i64 [[A]], 54
; CHECK-NEXT:    br i1 [[SHAMT_VALID]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL1:%.*]] = call i8* @malloc(i64 [[B]])
; CHECK-NEXT:    br i1 [[SHAMT_VALID]], label [[ALLOC_TRAP2:%.*]], label [[GUARDED_ALLOC1:%.*]]
; CHECK:       alloc.trap2:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc1:
; CHECK-NEXT:    ret i8* [[CALL1]]
;
  %b = shl nsw i64 1024, %a
  %call1 = call i8* @malloc(i64 %b)
  %call2 = call i8* @malloc(i64 %b)
  ret i8* %call1
}

define i8* @malloc_of_binop_chain(i64 %a) {
; CHECK-LABEL: @malloc_of_binop_chain(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 [[A:%.*]], i64 2)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    [[TMP4:%.*]] = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 [[TMP2]], i64 1)
; CHECK-NEXT:    [[TMP5:%.*]] = extractvalue { i64, i1 } [[TMP4]], 0
; CHECK-NEXT:    [[TMP6:%.*]] = extractvalue { i64, i1 } [[TMP4]], 1
; CHECK-NEXT:    [[TMP7:%.*]] = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 [[TMP5]], i64 3)
; CHECK-NEXT:    [[TMP8:%.*]] = extractvalue { i64, i1 } [[TMP7]], 0
; CHECK-NEXT:    [[TMP9:%.*]] = extractvalue { i64, i1 } [[TMP7]], 1
; CHECK-NEXT:    [[TMP10:%.*]] = or i1 [[TMP9]], [[TMP6]]
; CHECK-NEXT:    [[TMP11:%.*]] = or i1 [[TMP10]], [[TMP3]]
; CHECK-NEXT:    br i1 [[TMP11]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[TMP8]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = mul nsw i64 %a, 2
  %c = add nsw i64 %b, 1
  %d = sub nsw i64 %c, 3
  %call = call i8* @malloc(i64 %d)
  ret i8* %call
}

define i8* @malloc_with_reused_args(i64 %a, i64 %b) {
; CHECK-LABEL: @malloc_with_reused_args(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 [[A:%.*]], i64 1)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i64, i1 } [[TMP1]], 1
; CHECK-NEXT:    [[TMP4:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 [[TMP2]], i64 2)
; CHECK-NEXT:    [[TMP5:%.*]] = extractvalue { i64, i1 } [[TMP4]], 1
; CHECK-NEXT:    [[TMP6:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 [[TMP2]], i64 3)
; CHECK-NEXT:    [[TMP7:%.*]] = extractvalue { i64, i1 } [[TMP6]], 0
; CHECK-NEXT:    [[TMP8:%.*]] = extractvalue { i64, i1 } [[TMP6]], 1
; CHECK-NEXT:    [[TMP9:%.*]] = or i1 [[TMP5]], [[TMP3]]
; CHECK-NEXT:    br i1 [[TMP9]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[TMP10:%.*]] = or i1 [[TMP8]], [[TMP3]]
; CHECK-NEXT:    br i1 [[TMP10]], label [[ALLOC_TRAP2:%.*]], label [[GUARDED_ALLOC1:%.*]]
; CHECK:       alloc.trap2:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc1:
; CHECK-NEXT:    [[CALL2:%.*]] = call i8* @malloc(i64 [[TMP7]])
; CHECK-NEXT:    ret i8* [[CALL2]]
;
  %c = add nsw i64 %a, 1
  %d = mul nsw i64 %c, 2
  %e = mul nsw i64 %c, 3
  %call1 = call i8* @malloc(i64 %d)
  %call2 = call i8* @malloc(i64 %e)
  ret i8* %call2
}

define i8* @malloc_of_cast(i8 %a) {
; CHECK-LABEL: @malloc_of_cast(
; CHECK-NEXT:    [[TMP1:%.*]] = call { i8, i1 } @llvm.smul.with.overflow.i8(i8 [[A:%.*]], i8 2)
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i8, i1 } [[TMP1]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { i8, i1 } [[TMP1]], 1
; CHECK-NEXT:    [[C:%.*]] = zext i8 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = call { i32, i1 } @llvm.ssub.with.overflow.i32(i32 [[C]], i32 3)
; CHECK-NEXT:    [[TMP5:%.*]] = extractvalue { i32, i1 } [[TMP4]], 0
; CHECK-NEXT:    [[TMP6:%.*]] = extractvalue { i32, i1 } [[TMP4]], 1
; CHECK-NEXT:    [[E:%.*]] = sext i32 [[TMP5]] to i64
; CHECK-NEXT:    [[TMP7:%.*]] = or i1 [[TMP6]], [[TMP3]]
; CHECK-NEXT:    br i1 [[TMP7]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    [[CALL:%.*]] = call i8* @malloc(i64 [[E]])
; CHECK-NEXT:    ret i8* [[CALL]]
;
  %b = mul nsw i8 %a, 2
  %c = zext i8 %b to i32
  %d = sub nsw i32 %c, 3
  %e = sext i32 %d to i64
  %call = call i8* @malloc(i64 %e)
  ret i8* %call
}

define void @malloc_of_phi(i64 %switchval, i1 %loop) {
; CHECK-LABEL: @malloc_of_phi(
; CHECK-NEXT:  switch:
; CHECK-NEXT:    switch i64 [[SWITCHVAL:%.*]], label [[BB1:%.*]] [
; CHECK-NEXT:    i64 0, label [[BB2:%.*]]
; CHECK-NEXT:    i64 1, label [[BB3:%.*]]
; CHECK-NEXT:    i64 2, label [[BB4:%.*]]
; CHECK-NEXT:    ]
; CHECK:       bb1:
; CHECK-NEXT:    br label [[MALLOC:%.*]]
; CHECK:       bb2:
; CHECK-NEXT:    br label [[MALLOC]]
; CHECK:       bb3:
; CHECK-NEXT:    [[TMP0:%.*]] = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 [[SWITCHVAL]], i64 1)
; CHECK-NEXT:    [[TMP1:%.*]] = extractvalue { i64, i1 } [[TMP0]], 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP0]], 1
; CHECK-NEXT:    [[TMP3:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 [[TMP1]], i64 2)
; CHECK-NEXT:    [[TMP4:%.*]] = extractvalue { i64, i1 } [[TMP3]], 0
; CHECK-NEXT:    [[TMP5:%.*]] = extractvalue { i64, i1 } [[TMP3]], 1
; CHECK-NEXT:    [[TMP6:%.*]] = or i1 [[TMP5]], [[TMP2]]
; CHECK-NEXT:    br label [[MALLOC]]
; CHECK:       bb4:
; CHECK-NEXT:    [[T2:%.*]] = phi i64 [ [[SWITCHVAL]], [[SWITCH:%.*]] ], [ [[MALLOC_PHI:%.*]], [[GUARDED_ALLOC2:%.*]] ]
; CHECK-NEXT:    [[TMP7:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 [[T2]], i64 2)
; CHECK-NEXT:    [[TMP8:%.*]] = extractvalue { i64, i1 } [[TMP7]], 0
; CHECK-NEXT:    [[TMP9:%.*]] = extractvalue { i64, i1 } [[TMP7]], 1
; CHECK-NEXT:    br label [[MALLOC]]
; CHECK:       malloc:
; CHECK-NEXT:    [[MALLOC_PHI]] = phi i64 [ 0, [[BB1]] ], [ undef, [[BB2]] ], [ [[TMP4]], [[BB3]] ], [ [[TMP8]], [[BB4]] ]
; CHECK-NEXT:    [[DID_OVERFLOW1:%.*]] = phi i1 [ false, [[BB1]] ], [ true, [[BB2]] ], [ [[TMP6]], [[BB3]] ], [ [[TMP9]], [[BB4]] ]
; CHECK-NEXT:    br i1 [[DID_OVERFLOW1]], label [[ALLOC_TRAP:%.*]], label [[GUARDED_ALLOC:%.*]]
; CHECK:       alloc.trap:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc:
; CHECK-NEXT:    br i1 [[DID_OVERFLOW1]], label [[ALLOC_TRAP3:%.*]], label [[GUARDED_ALLOC2]]
; CHECK:       alloc.trap3:
; CHECK-NEXT:    call void @llvm.trap()
; CHECK-NEXT:    unreachable
; CHECK:       guarded.alloc2:
; CHECK-NEXT:    br i1 [[LOOP:%.*]], label [[BB4]], label [[EXIT:%.*]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
;
switch:
  switch i64 %switchval, label %bb1 [
  i64 0, label %bb2
  i64 1, label %bb3
  i64 2, label %bb4
  ]

bb1:
  br label %malloc

bb2:
  br label %malloc

bb3:
  %t1 = add nsw i64 %switchval, 1
  %n1 = mul nsw i64 %t1, 2
  br label %malloc

bb4:
  %t2 = phi i64 [ %switchval, %switch ], [ %malloc_phi, %malloc ]
  %n2 = mul nsw i64 %t2, 2
  br label %malloc

malloc:
  %malloc_phi = phi i64 [ 0, %bb1 ],     ; No incoming overflow bits.
  [ undef, %bb2 ], ; Exactly one incoming overflow bit.
  [ %n1, %bb3 ],   ; Multiple incoming overflow bits.
  [ %n2, %bb4 ]    ; Loop in the CFG.

  %call1 = call i8* @malloc(i64 %malloc_phi)

  ; Test overflow result reuse.
  %call2 = call i8* @malloc(i64 %malloc_phi)

  br i1 %loop, label %bb4, label %exit

exit:
  ret void
}
